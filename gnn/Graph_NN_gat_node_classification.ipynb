{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graph NN gat_node_classification",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ankur3107/Machine-Learning-Notes/blob/master/gnn/Graph_NN_gat_node_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M5XkWfW4428"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "[Graph neural networks](https://en.wikipedia.org/wiki/Graph_neural_network)\n",
        "is the prefered neural network architecture for processing data structured as\n",
        "graphs (for example, social networks or molecule structures), yielding\n",
        "better results than fully-connected networks or convolutional networks.\n",
        "\n",
        "In this tutorial, we will implement a specific graph neural network known as a\n",
        "[Graph Attention Network](https://arxiv.org/abs/1710.10903) (GAT) to predict labels of\n",
        "scientific papers based on the papers they cite (using the\n",
        "[Cora](https://linqs.soe.ucsc.edu/data) dataset).\n",
        "\n",
        "### References\n",
        "\n",
        "For more information on GAT, see the original paper\n",
        "[Graph Attention Networks](https://arxiv.org/abs/1710.10903) as well as\n",
        "[DGL's Graph Attention Networks](https://docs.dgl.ai/en/0.4.x/tutorials/models/1_gnn/9_gat.html)\n",
        "documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilSV0bqG4428"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-5uU2Sz4428"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option(\"display.max_columns\", 6)\n",
        "pd.set_option(\"display.max_rows\", 6)\n",
        "np.random.seed(2)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llUkgnaq4429"
      },
      "source": [
        "## Obtain the dataset\n",
        "\n",
        "The preparation of the [Cora dataset](https://linqs.soe.ucsc.edu/data) follows that of the\n",
        "[Node classification with Graph Neural Networks](https://keras.io/examples/graph/gnn_citations/)\n",
        "tutorial. Refer to this tutorial for more details on the dataset and exploratory data analysis.\n",
        "In brief, the Cora dataset consists of two files: `cora.cites` which contains *directed links* (citations) between\n",
        "papers; and `cora.content` which contains *features* of the corresponding papers and one\n",
        "of seven labels (the *subject* of the paper)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCMd7r_q4429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a628d0dd-a570-4389-a043-84c0712952a4"
      },
      "source": [
        "zip_file = keras.utils.get_file(\n",
        "    fname=\"cora.tgz\",\n",
        "    origin=\"https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\",\n",
        "    extract=True,\n",
        ")\n",
        "\n",
        "data_dir = os.path.join(os.path.dirname(zip_file), \"cora\")\n",
        "\n",
        "citations = pd.read_csv(\n",
        "    os.path.join(data_dir, \"cora.cites\"),\n",
        "    sep=\"\\t\",\n",
        "    header=None,\n",
        "    names=[\"target\", \"source\"],\n",
        ")\n",
        "\n",
        "papers = pd.read_csv(\n",
        "    os.path.join(data_dir, \"cora.content\"),\n",
        "    sep=\"\\t\",\n",
        "    header=None,\n",
        "    names=[\"paper_id\"] + [f\"term_{idx}\" for idx in range(1433)] + [\"subject\"],\n",
        ")\n",
        "\n",
        "class_values = sorted(papers[\"subject\"].unique())\n",
        "class_idx = {name: id for id, name in enumerate(class_values)}\n",
        "paper_idx = {name: idx for idx, name in enumerate(sorted(papers[\"paper_id\"].unique()))}\n",
        "\n",
        "papers[\"paper_id\"] = papers[\"paper_id\"].apply(lambda name: paper_idx[name])\n",
        "citations[\"source\"] = citations[\"source\"].apply(lambda name: paper_idx[name])\n",
        "citations[\"target\"] = citations[\"target\"].apply(lambda name: paper_idx[name])\n",
        "papers[\"subject\"] = papers[\"subject\"].apply(lambda value: class_idx[value])\n",
        "\n",
        "print(citations)\n",
        "\n",
        "print(papers)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\n",
            "172032/168052 [==============================] - 0s 1us/step\n",
            "180224/168052 [================================] - 0s 1us/step\n",
            "      target  source\n",
            "0          0      21\n",
            "1          0     905\n",
            "2          0     906\n",
            "...      ...     ...\n",
            "5426    1874    2586\n",
            "5427    1876    1874\n",
            "5428    1897    2707\n",
            "\n",
            "[5429 rows x 2 columns]\n",
            "      paper_id  term_0  term_1  ...  term_1431  term_1432  subject\n",
            "0          462       0       0  ...          0          0        2\n",
            "1         1911       0       0  ...          0          0        5\n",
            "2         2002       0       0  ...          0          0        4\n",
            "...        ...     ...     ...  ...        ...        ...      ...\n",
            "2705      2372       0       0  ...          0          0        1\n",
            "2706       955       0       0  ...          0          0        0\n",
            "2707       376       0       0  ...          0          0        2\n",
            "\n",
            "[2708 rows x 1435 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "4kccFe745TLx",
        "outputId": "bb6d0be5-e83d-4662-ec21-ba5ddf2d33eb"
      },
      "source": [
        "citations.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1940</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target  source\n",
              "0       0      21\n",
              "1       0     905\n",
              "2       0     906\n",
              "3       0    1909\n",
              "4       0    1940"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "p3U3ANuv5W_5",
        "outputId": "1de37683-d444-4595-b38c-ae93b0df3965"
      },
      "source": [
        "papers.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_id</th>\n",
              "      <th>term_0</th>\n",
              "      <th>term_1</th>\n",
              "      <th>...</th>\n",
              "      <th>term_1431</th>\n",
              "      <th>term_1432</th>\n",
              "      <th>subject</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>462</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1911</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>248</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>519</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1435 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   paper_id  term_0  term_1  ...  term_1431  term_1432  subject\n",
              "0       462       0       0  ...          0          0        2\n",
              "1      1911       0       0  ...          0          0        5\n",
              "2      2002       0       0  ...          0          0        4\n",
              "3       248       0       0  ...          0          0        4\n",
              "4       519       0       0  ...          0          0        3\n",
              "\n",
              "[5 rows x 1435 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYlLTPQ55rWL",
        "outputId": "d054995c-687c-446f-a62e-c17bfed88d84"
      },
      "source": [
        "class_idx"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Case_Based': 0,\n",
              " 'Genetic_Algorithms': 1,\n",
              " 'Neural_Networks': 2,\n",
              " 'Probabilistic_Methods': 3,\n",
              " 'Reinforcement_Learning': 4,\n",
              " 'Rule_Learning': 5,\n",
              " 'Theory': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-NxKxOs442-"
      },
      "source": [
        "### Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKN4IjOf442-"
      },
      "source": [
        "# Obtain random indices\n",
        "random_indices = np.random.permutation(range(papers.shape[0]))\n",
        "\n",
        "# 50/50 split\n",
        "train_data = papers.iloc[random_indices[: len(random_indices) // 2]]\n",
        "test_data = papers.iloc[random_indices[len(random_indices) // 2 :]]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlLdHbS5442-"
      },
      "source": [
        "### Prepare the graph data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6lPjtCM442-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e118444-ae01-4147-f605-2de964f15c9a"
      },
      "source": [
        "# Obtain paper indices which will be used to gather node states\n",
        "# from the graph later on when training the model\n",
        "train_indices = train_data[\"paper_id\"].to_numpy()\n",
        "test_indices = test_data[\"paper_id\"].to_numpy()\n",
        "\n",
        "# Obtain ground truth labels corresponding to each paper_id\n",
        "train_labels = train_data[\"subject\"].to_numpy()\n",
        "test_labels = test_data[\"subject\"].to_numpy()\n",
        "\n",
        "# Define graph, namely an edge tensor and a node feature tensor\n",
        "edges = tf.convert_to_tensor(citations[[\"source\", \"target\"]])\n",
        "node_features = tf.convert_to_tensor(papers.sort_values(\"paper_id\").iloc[:, 1:-1])\n",
        "\n",
        "# Print shapes of the graph\n",
        "print(\"Edges shape:\\t\\t\", edges.shape)\n",
        "print(\"Node features shape:\", node_features.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edges shape:\t\t (5429, 2)\n",
            "Node features shape: (2708, 1433)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "zWEiTrS_6XIR",
        "outputId": "f7f53ba1-f2c8-404a-9239-d95f346af1dd"
      },
      "source": [
        "papers.sort_values(\"paper_id\").iloc[:, 1:-1]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term_0</th>\n",
              "      <th>term_1</th>\n",
              "      <th>term_2</th>\n",
              "      <th>...</th>\n",
              "      <th>term_1430</th>\n",
              "      <th>term_1431</th>\n",
              "      <th>term_1432</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1955</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1956</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1686</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2708 rows × 1433 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      term_0  term_1  term_2  ...  term_1430  term_1431  term_1432\n",
              "163        0       0       0  ...          0          0          0\n",
              "168        0       0       0  ...          0          0          0\n",
              "552        0       0       0  ...          0          0          0\n",
              "...      ...     ...     ...  ...        ...        ...        ...\n",
              "1955       0       0       0  ...          0          0          0\n",
              "1956       0       0       0  ...          0          0          0\n",
              "1686       0       0       0  ...          0          0          0\n",
              "\n",
              "[2708 rows x 1433 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCwLJPKp442-"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "GAT takes as input a graph (namely an edge tensor and a node feature tensor) and\n",
        "outputs \\[updated\\] node states. The node states are, for each source node, neighborhood\n",
        "aggregated information of *N*-hops (where *N* is decided by the number of layers of the\n",
        "GAT). Importantly, in contrast to the\n",
        "[graph convolutional network](https://arxiv.org/abs/1609.02907) (GCN)\n",
        "the GAT make use of attention machanisms\n",
        "to aggregate information from neighboring nodes. In other words, instead of simply\n",
        "averaging/summing node states from neighbors to the source node, GAT first applies\n",
        "normalized attention scores to each neighbor node state and then sums."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKlSXDEI442_"
      },
      "source": [
        "### (Multi-head) graph attention layer\n",
        "\n",
        "The GAT model implements multi-head graph attention layers. The `MultiHeadGraphAttention`\n",
        "layer is simply a concatenation (or averaging) of multiple graph attention layers\n",
        "(`GraphAttention`), each with separate learnable weights `W`. The `GraphAttention` layer\n",
        "does the following:\n",
        "\n",
        "Consider inputs node states `h^{l}` which are linearly transformed by `W^{l}`, resulting in `z^{l}`.\n",
        "\n",
        "For each source node:\n",
        "\n",
        "1. Computes pair-wise attention scores `a^{l}^{T}(z^{l}_{i}||z^{l}_{j})` for all `j`,\n",
        "resulting in `e_{ij}` (for all `j`).\n",
        "`||` denotes a concatenation, `_{i}` corresponds to the source node, and `_{j}`\n",
        "corresponds to a given 1-hop neighbor node.\n",
        "2. Normalizes `e_{ij}` via softmax, so as the sum of incoming edges' attention scores\n",
        "to the source node (`sum_{k}{e_{norm}_{ik}}`) will add up to 1.\n",
        "(Notice, in this tutorial, *incoming edges* are defined as edges\n",
        "pointing from the *source paper* (the paper *citing*) to the *target paper* (the paper *cited*),\n",
        "which is counter inuitive. However, this seems to work better in practice.\n",
        "In other words, we want to learn the label of the source paper based on what it cites (target papers).)\n",
        "3. Applies attention scores `e_{norm}_{ij}` to `z_{j}`\n",
        "and adds it to the new source node state `h^{l+1}_{i}`, for all `j`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DILWJjOi442_"
      },
      "source": [
        "\n",
        "class GraphAttention(layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        units,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        kernel_regularizer=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
        "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(input_shape[0][-1], self.units),\n",
        "            trainable=True,\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "        )\n",
        "        self.kernel_attention = self.add_weight(\n",
        "            shape=(self.units * 2, 1),\n",
        "            trainable=True,\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "        )\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        node_features, edges = inputs\n",
        "\n",
        "        # Linearly transform node features (node states)\n",
        "        node_features_transformed = tf.matmul(node_features, self.kernel)\n",
        "\n",
        "        # (1) Compute pair-wise attention scores\n",
        "        node_features_expanded = tf.gather(node_features_transformed, edges)\n",
        "        node_features_expanded = tf.reshape(\n",
        "            node_features_expanded, (tf.shape(edges)[0], -1)\n",
        "        )\n",
        "        attention_scores = tf.nn.leaky_relu(\n",
        "            tf.matmul(node_features_expanded, self.kernel_attention)\n",
        "        )\n",
        "        attention_scores = tf.squeeze(attention_scores, -1)\n",
        "\n",
        "        # (2) Normalize attention scores\n",
        "        attention_scores = tf.math.exp(tf.clip_by_value(attention_scores, -2, 2))\n",
        "        attention_scores_sum = tf.math.unsorted_segment_sum(\n",
        "            data=attention_scores,\n",
        "            segment_ids=edges[:, 0],\n",
        "            num_segments=tf.reduce_max(edges[:, 0]) + 1,\n",
        "        )\n",
        "        attention_scores_sum = tf.repeat(\n",
        "            attention_scores_sum, tf.math.bincount(tf.cast(edges[:, 0], \"int32\"))\n",
        "        )\n",
        "        attention_scores_norm = attention_scores / attention_scores_sum\n",
        "\n",
        "        # (3) Gather node states of neighbors, apply attention scores and aggregate\n",
        "        node_features_neighbors = tf.gather(node_features_transformed, edges[:, 1])\n",
        "        out = tf.math.unsorted_segment_sum(\n",
        "            data=node_features_neighbors * attention_scores_norm[:, tf.newaxis],\n",
        "            segment_ids=edges[:, 0],\n",
        "            num_segments=tf.shape(node_features)[0],\n",
        "        )\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadGraphAttention(layers.Layer):\n",
        "    def __init__(self, units, num_heads=8, merge_type=\"concat\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_heads = num_heads\n",
        "        self.merge_type = merge_type\n",
        "        self.attention_layers = [GraphAttention(units) for _ in range(num_heads)]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        atom_features, pair_indices = inputs\n",
        "\n",
        "        # Obtain outputs from each attention head\n",
        "        outputs = [\n",
        "            attention_layer([atom_features, pair_indices])\n",
        "            for attention_layer in self.attention_layers\n",
        "        ]\n",
        "        # Concatenate or average the node states from each head\n",
        "        if self.merge_type == \"concat\":\n",
        "            outputs = tf.concat(outputs, axis=-1)\n",
        "        else:\n",
        "            outputs = tf.reduce_mean(tf.stack(outputs, axis=-1), axis=-1)\n",
        "        # Activate and return node states\n",
        "        return tf.nn.relu(outputs)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlDSsobf442_"
      },
      "source": [
        "### Implement training logic with custom `train_step`, `test_step`, and `predict_step` methods\n",
        "\n",
        "Notice, the GAT model operates on the entire graph (namely, `node_features` and\n",
        "`edges`) in all phases (training, validation and testing). Hence, `node_features` and\n",
        "`edges` are passed to the constructor of the `keras.Model` and used as attributes.\n",
        "The difference between the phases are the indices (and labels), which gathers\n",
        "certain output units (`tf.gather(outputs, indices)`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPXjoY1o442_"
      },
      "source": [
        "\n",
        "class GraphAttentionNetwork(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_features,\n",
        "        edges,\n",
        "        hidden_units,\n",
        "        num_heads,\n",
        "        num_layers,\n",
        "        output_dim,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.node_features = node_features\n",
        "        self.edges = edges\n",
        "        self.preprocess = layers.Dense(hidden_units * num_heads, activation=\"relu\")\n",
        "        self.attention_layers = [\n",
        "            MultiHeadGraphAttention(hidden_units, num_heads) for _ in range(num_layers)\n",
        "        ]\n",
        "        self.output_layer = layers.Dense(output_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        node_features, edges = inputs\n",
        "        x = self.preprocess(node_features)\n",
        "        for attention_layer in self.attention_layers:\n",
        "            x = attention_layer([x, edges]) + x\n",
        "        outputs = self.output_layer(x)\n",
        "        return outputs\n",
        "\n",
        "    def train_step(self, data):\n",
        "        indices, labels = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            outputs = self([self.node_features, self.edges])\n",
        "            # Compute loss\n",
        "            loss = self.compiled_loss(labels, tf.gather(outputs, indices))\n",
        "        # Compute gradients\n",
        "        grads = tape.gradient(loss, self.trainable_weights)\n",
        "        # Apply gradients (update weights)\n",
        "        optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        # Update metric(s)\n",
        "        self.compiled_metrics.update_state(labels, tf.gather(outputs, indices))\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def predict_step(self, data):\n",
        "        indices = data\n",
        "        # Forward pass\n",
        "        outputs = self([self.node_features, self.edges])\n",
        "        # Compute probabilities\n",
        "        return tf.nn.softmax(tf.gather(outputs, indices))\n",
        "\n",
        "    def test_step(self, data):\n",
        "        indices, labels = data\n",
        "        # Forward pass\n",
        "        outputs = self([self.node_features, self.edges])\n",
        "        # Compute loss\n",
        "        loss = self.compiled_loss(labels, tf.gather(outputs, indices))\n",
        "        # Update metric(s)\n",
        "        self.compiled_metrics.update_state(labels, tf.gather(outputs, indices))\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE1TovaB443A"
      },
      "source": [
        "### Train and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDeAvvyB443A"
      },
      "source": [
        "# Define hyper-parameters\n",
        "HIDDEN_UNITS = 100\n",
        "NUM_HEADS = 8\n",
        "NUM_LAYERS = 3\n",
        "OUTPUT_DIM = len(class_values)\n",
        "\n",
        "NUM_EPOCHS = 100\n",
        "BATCH_SIZE = 256\n",
        "VALIDATION_SPLIT = 0.1\n",
        "LEARNING_RATE = 3e-1\n",
        "MOMENTUM = 0.9\n",
        "\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = keras.optimizers.SGD(LEARNING_RATE, momentum=MOMENTUM)\n",
        "accuracy_fn = keras.metrics.SparseCategoricalAccuracy(name=\"acc\")\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_acc\", min_delta=1e-5, patience=5, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Build model\n",
        "gat_model = GraphAttentionNetwork(\n",
        "    node_features, edges, HIDDEN_UNITS, NUM_HEADS, NUM_LAYERS, OUTPUT_DIM\n",
        ")\n",
        "\n",
        "# Compile model\n",
        "gat_model.compile(loss=loss_fn, optimizer=optimizer, metrics=[accuracy_fn])\n",
        "\n",
        "gat_model.fit(\n",
        "    x=train_indices,\n",
        "    y=train_labels,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=2,\n",
        ")\n",
        "\n",
        "_, test_accuracy = gat_model.evaluate(x=test_indices, y=test_labels, verbose=0)\n",
        "\n",
        "print(\"--\" * 38 + f\"\\nTest Accuracy {test_accuracy*100:.1f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ioqvuhx17c3w",
        "outputId": "7440c6c8-653a-4a38-fe17-113809ea55ef"
      },
      "source": [
        "print(\"--\" * 38 + f\"\\nTest Accuracy {test_accuracy*100:.1f}%\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------\n",
            "Test Accuracy 84.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckctzK3B443A"
      },
      "source": [
        "### Predict (probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmIRbGk1443B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f16b8f-7cb7-4c72-d01b-5218d68f7167"
      },
      "source": [
        "test_probs = gat_model.predict(x=test_indices)\n",
        "\n",
        "mapping = {v: k for (k, v) in class_idx.items()}\n",
        "\n",
        "for i, (probs, label) in enumerate(zip(test_probs[:10], test_labels[:10])):\n",
        "    print(f\"Example {i+1}: {mapping[label]}\")\n",
        "    for j, c in zip(probs, class_idx.keys()):\n",
        "        print(f\"\\tProbability of {c: <24} = {j*100:7.3f}%\")\n",
        "    print(\"---\" * 20)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1: Probabilistic_Methods\n",
            "\tProbability of Case_Based               =   0.001%\n",
            "\tProbability of Genetic_Algorithms       =   0.000%\n",
            "\tProbability of Neural_Networks          =   0.268%\n",
            "\tProbability of Probabilistic_Methods    =  99.730%\n",
            "\tProbability of Reinforcement_Learning   =   0.000%\n",
            "\tProbability of Rule_Learning            =   0.000%\n",
            "\tProbability of Theory                   =   0.002%\n",
            "------------------------------------------------------------\n",
            "Example 2: Genetic_Algorithms\n",
            "\tProbability of Case_Based               =   0.000%\n",
            "\tProbability of Genetic_Algorithms       = 100.000%\n",
            "\tProbability of Neural_Networks          =   0.000%\n",
            "\tProbability of Probabilistic_Methods    =   0.000%\n",
            "\tProbability of Reinforcement_Learning   =   0.000%\n",
            "\tProbability of Rule_Learning            =   0.000%\n",
            "\tProbability of Theory                   =   0.000%\n",
            "------------------------------------------------------------\n",
            "Example 3: Theory\n",
            "\tProbability of Case_Based               =   3.069%\n",
            "\tProbability of Genetic_Algorithms       =   0.254%\n",
            "\tProbability of Neural_Networks          =   0.261%\n",
            "\tProbability of Probabilistic_Methods    =  11.087%\n",
            "\tProbability of Reinforcement_Learning   =   0.183%\n",
            "\tProbability of Rule_Learning            =  12.639%\n",
            "\tProbability of Theory                   =  72.507%\n",
            "------------------------------------------------------------\n",
            "Example 4: Neural_Networks\n",
            "\tProbability of Case_Based               =   0.000%\n",
            "\tProbability of Genetic_Algorithms       =   0.000%\n",
            "\tProbability of Neural_Networks          =  99.996%\n",
            "\tProbability of Probabilistic_Methods    =   0.003%\n",
            "\tProbability of Reinforcement_Learning   =   0.000%\n",
            "\tProbability of Rule_Learning            =   0.000%\n",
            "\tProbability of Theory                   =   0.000%\n",
            "------------------------------------------------------------\n",
            "Example 5: Theory\n",
            "\tProbability of Case_Based               =  28.255%\n",
            "\tProbability of Genetic_Algorithms       =   0.114%\n",
            "\tProbability of Neural_Networks          =   6.925%\n",
            "\tProbability of Probabilistic_Methods    =   4.147%\n",
            "\tProbability of Reinforcement_Learning   =   0.051%\n",
            "\tProbability of Rule_Learning            =  15.454%\n",
            "\tProbability of Theory                   =  45.054%\n",
            "------------------------------------------------------------\n",
            "Example 6: Genetic_Algorithms\n",
            "\tProbability of Case_Based               =   0.000%\n",
            "\tProbability of Genetic_Algorithms       = 100.000%\n",
            "\tProbability of Neural_Networks          =   0.000%\n",
            "\tProbability of Probabilistic_Methods    =   0.000%\n",
            "\tProbability of Reinforcement_Learning   =   0.000%\n",
            "\tProbability of Rule_Learning            =   0.000%\n",
            "\tProbability of Theory                   =   0.000%\n",
            "------------------------------------------------------------\n",
            "Example 7: Neural_Networks\n",
            "\tProbability of Case_Based               =   0.318%\n",
            "\tProbability of Genetic_Algorithms       =   0.284%\n",
            "\tProbability of Neural_Networks          =  97.862%\n",
            "\tProbability of Probabilistic_Methods    =   0.724%\n",
            "\tProbability of Reinforcement_Learning   =   0.347%\n",
            "\tProbability of Rule_Learning            =   0.123%\n",
            "\tProbability of Theory                   =   0.342%\n",
            "------------------------------------------------------------\n",
            "Example 8: Genetic_Algorithms\n",
            "\tProbability of Case_Based               =   0.000%\n",
            "\tProbability of Genetic_Algorithms       =  99.994%\n",
            "\tProbability of Neural_Networks          =   0.000%\n",
            "\tProbability of Probabilistic_Methods    =   0.000%\n",
            "\tProbability of Reinforcement_Learning   =   0.006%\n",
            "\tProbability of Rule_Learning            =   0.000%\n",
            "\tProbability of Theory                   =   0.000%\n",
            "------------------------------------------------------------\n",
            "Example 9: Theory\n",
            "\tProbability of Case_Based               =   0.256%\n",
            "\tProbability of Genetic_Algorithms       =   0.002%\n",
            "\tProbability of Neural_Networks          =   0.049%\n",
            "\tProbability of Probabilistic_Methods    =   7.909%\n",
            "\tProbability of Reinforcement_Learning   =   0.000%\n",
            "\tProbability of Rule_Learning            =   0.810%\n",
            "\tProbability of Theory                   =  90.974%\n",
            "------------------------------------------------------------\n",
            "Example 10: Case_Based\n",
            "\tProbability of Case_Based               = 100.000%\n",
            "\tProbability of Genetic_Algorithms       =   0.000%\n",
            "\tProbability of Neural_Networks          =   0.000%\n",
            "\tProbability of Probabilistic_Methods    =   0.000%\n",
            "\tProbability of Reinforcement_Learning   =   0.000%\n",
            "\tProbability of Rule_Learning            =   0.000%\n",
            "\tProbability of Theory                   =   0.000%\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAZUuv-T443B"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "The results look OK! The GAT model seems to correctly predict the subjects of the papers,\n",
        "based on what they cite, about 80-85% of the time. Further improvements could be\n",
        "made by fine-tuning the hyper-parameters of the GAT. For instance, try changing the number of layers,\n",
        "the number of hidden units, or the optimizer/learning rate; add regularization (e.g., dropout);\n",
        "or modify the preprocessing step. We could also try to implement *self-loops*\n",
        "(i.e., paper X cites paper X) and/or make the graph *undirected*."
      ]
    }
  ]
}