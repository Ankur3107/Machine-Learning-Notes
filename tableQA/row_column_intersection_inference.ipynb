{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "row-column-intersection inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO0c9sWaiGJDP+XSqKi1nGb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ankur3107/Machine-Learning-Notes/blob/master/tableQA/row_column_intersection_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3yO3rnVT_ES",
        "outputId": "7c0888a2-08dc-4a93-8850-ef7cab467625"
      },
      "source": [
        "!pip install transformers ujson scikit-learn sentencePiece"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.11.2)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (4.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: sentencePiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.17)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh1bK-yMULNo"
      },
      "source": [
        "from typing import Any, List, Dict, Tuple\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    AlbertConfig, AlbertForSequenceClassification, AlbertTokenizer,\n",
        "    XLMRobertaConfig, XLMRobertaForSequenceClassification, XLMRobertaTokenizer,\n",
        "    PreTrainedModel\n",
        ")\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1CmiwcGUUNA"
      },
      "source": [
        "class TableQAOptions:\n",
        "    def __init__(self):\n",
        "        self.model_type = 'albert'\n",
        "        self.tokenizer = 'albert-base-v2'\n",
        "        self.row_model = 'michaelrglass/albert-base-rci-wikisql-row'\n",
        "        self.col_model = 'michaelrglass/albert-base-rci-wikisql-col'\n",
        "        self.max_seq_length = 128\n",
        "        self.batch_size = 16\n",
        "        self.top_k = 5\n",
        "        self.device = 'cpu'\n",
        "\n",
        "class RCISystem(object):\n",
        "    \"\"\"\n",
        "    Interactive TableQA system using the Row Column Intersection Model.\n",
        "    https://www.aclweb.org/anthology/2021.naacl-main.96/\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, opts: TableQAOptions):\n",
        "        self.opts = opts\n",
        "        self._device = torch.device(self.opts.device)\n",
        "        # select model class\n",
        "        model_classes = {\n",
        "            \"albert\": (AlbertConfig, AlbertForSequenceClassification, AutoTokenizer),\n",
        "            \"xlmroberta\": (XLMRobertaConfig, XLMRobertaForSequenceClassification, XLMRobertaTokenizer),\n",
        "        }\n",
        "        config_class, model_class, tokenizer_class = model_classes[self.opts.model_type.lower()]\n",
        "        # load tokenizer and models\n",
        "        self.tokenizer = tokenizer_class.from_pretrained(self.opts.tokenizer)\n",
        "        self.row_model = self._load(model_class, self.opts.row_model)\n",
        "        self.col_model = self._load(model_class, self.opts.col_model)\n",
        "\n",
        "    def _load(self, model_class, model_name_or_path: str) -> PreTrainedModel:\n",
        "        model = model_class.from_pretrained(model_name_or_path)\n",
        "        model.to(self._device)\n",
        "        model.eval()\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def row_column_strings(header: List[str], rows: List[List[str]]) -> Tuple[List[str], List[str]]:\n",
        "        row_reps = []\n",
        "        col_reps = []\n",
        "        cols = [[str(h)] for h in header]\n",
        "        for row in rows:\n",
        "            row_rep = ' * '.join([h + ' : ' + str(c) for h, c in zip(header, row)])\n",
        "            row_reps.append(row_rep)\n",
        "            for ci, cell in enumerate(row):\n",
        "                cols[ci].append(str(cell))\n",
        "        for col in cols:\n",
        "            col_rep = ' * '.join(col)\n",
        "            col_reps.append(col_rep)\n",
        "        return row_reps, col_reps\n",
        "\n",
        "    def _repr_to_input(self, query: str, reprs: List[str]) -> Dict[str, torch.Tensor]:\n",
        "        inputs = self.tokenizer.batch_encode_plus(batch_text_or_text_pairs=[(query, rr) for rr in reprs],\n",
        "                                                  max_length=self.opts.max_seq_length,\n",
        "                                                  add_special_tokens=True, return_tensors='pt',\n",
        "                                                  padding='longest', truncation=True)\n",
        "        return {k: t.to(self._device) for k, t in inputs.items()}\n",
        "\n",
        "    def _top_k_cells(self, row_logits: np.ndarray, col_logits: np.ndarray) -> List[Tuple[int, int, float]]:\n",
        "        all_scores = []\n",
        "        for ri, rs in enumerate(row_logits):\n",
        "            for ci, cs in enumerate(col_logits):\n",
        "                s = float(rs + cs)\n",
        "                all_scores.append((ri, ci, s))\n",
        "        all_scores.sort(key=lambda x: x[2], reverse=True)\n",
        "        return all_scores[0:self.opts.top_k]\n",
        "\n",
        "    def _batched_score(self, query, reps, model):\n",
        "        logits = np.zeros(len(reps), dtype=np.float32)\n",
        "        for start in range(0, len(reps), self.opts.batch_size):\n",
        "            end = start + self.opts.batch_size\n",
        "            with torch.no_grad():\n",
        "                inputs = self._repr_to_input(query, reps[start:end])\n",
        "                logits[start:end] = model(**inputs)[0].detach().cpu().numpy()[:, 1]\n",
        "        return logits\n",
        "\n",
        "    def _apply(self, query: str, header: List[str], rows: List[List[str]]) -> List[Tuple[int, int, float]]:\n",
        "        row_reps, col_reps = RCISystem.row_column_strings(header, rows)\n",
        "        col_logits = self._batched_score(query, col_reps, self.col_model)\n",
        "        row_logits = self._batched_score(query, row_reps, self.row_model)\n",
        "        return self._top_k_cells(row_logits, col_logits)\n",
        "\n",
        "    def get_answers(self, question: str, header: List[str], rows: List[List[str]]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "                Computes the answers to the question in the passage\n",
        "                :param str question: the question\n",
        "                :param List[str] header: the table header\n",
        "                :param List[List[str]] rows: the table rows\n",
        "                :return: Cell prediction answers in descending score order\n",
        "                :rtype: List[Dict[str, Any]]\n",
        "        \"\"\"\n",
        "        cells = self._apply(question, header, rows)\n",
        "        # return a list of dicts\n",
        "        return [{'row_ndx': ri, 'col_ndx': ci, 'confidence_score': s, 'text': rows[ri][ci]} for ri, ci, s in cells]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSwVDMvJUXSt",
        "outputId": "21821246-1110-4e47-a35f-84fb4c5d0219"
      },
      "source": [
        "opts = TableQAOptions()\n",
        "rci = RCISystem(opts)\n",
        "#tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
        "print(rci.get_answers(\n",
        "    'Who won the race in June?',\n",
        "    ['Participant', 'Race', 'Date'],\n",
        "    [['Michael', 'Runathon', 'June 10, 2020'],\n",
        "      ['Mustafa', 'Runathon', 'Sept 3, 2020'],\n",
        "      ['Alfio', 'Runathon', 'Jan 1, 2021'],\n",
        "      ]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'row_ndx': 0, 'col_ndx': 0, 'confidence_score': -7.197484016418457, 'text': 'Michael'}, {'row_ndx': 1, 'col_ndx': 0, 'confidence_score': -7.743732929229736, 'text': 'Mustafa'}, {'row_ndx': 2, 'col_ndx': 0, 'confidence_score': -7.756281852722168, 'text': 'Alfio'}, {'row_ndx': 0, 'col_ndx': 2, 'confidence_score': -9.112548828125, 'text': 'June 10, 2020'}, {'row_ndx': 0, 'col_ndx': 1, 'confidence_score': -9.140498161315918, 'text': 'Runathon'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X_6ZFqiUalj",
        "outputId": "efe19c13-56b3-4c0e-df4c-5f0b1c04e4b0"
      },
      "source": [
        "print(rci.get_answers(\n",
        "    'Who won the race at 3 sept?',\n",
        "    ['Participant', 'Race', 'Date'],\n",
        "    [['Michael', 'Runathon', 'June 10, 2020'],\n",
        "      ['Mustafa', 'Runathon', 'Sept 3, 2020'],\n",
        "      ['Alfio', 'Runathon', 'Jan 1, 2021'],\n",
        "      ]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'row_ndx': 1, 'col_ndx': 0, 'confidence_score': -7.258375644683838, 'text': 'Mustafa'}, {'row_ndx': 2, 'col_ndx': 0, 'confidence_score': -7.339871883392334, 'text': 'Alfio'}, {'row_ndx': 0, 'col_ndx': 0, 'confidence_score': -7.4633870124816895, 'text': 'Michael'}, {'row_ndx': 1, 'col_ndx': 2, 'confidence_score': -9.400774955749512, 'text': 'Sept 3, 2020'}, {'row_ndx': 2, 'col_ndx': 2, 'confidence_score': -9.482271194458008, 'text': 'Jan 1, 2021'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLRuFHKKVca0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}